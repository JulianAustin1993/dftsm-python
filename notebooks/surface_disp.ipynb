{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), '..','src'))\n",
    "\n",
    "import numpy as np\n",
    "from basis import Bspline\n",
    "from fda import fpca, mafr\n",
    "from utils import GP, Matern, whiteNoise, structNoise\n",
    "import tqdm\n",
    "np.random.seed(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Surface displacement Dataset\n",
    "\n",
    "In this notebook we forecast our surface displacement data set, described [here]. We use the same technique as descibed in this [notebook]. The only difference being we can now only add different simulations of the noise component to our one real world dataset. \n",
    "\n",
    "[here] ./data_generation.ipynb\n",
    "[notebook] ./simulation.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "In the following codeblock we setup the domain parameters, a basis system for our functional decomposition and the various inner products needed for the decomposition methodology. These are constant and unaffected by the noise processes so we can calculate them just once for the whole notebook. In particular we set our basis to have $25$ basis functions in each dimension of our spatial functional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Domain parameters\n",
    "S1, S2, T = 520, 531, 128\n",
    "t = np.linspace(0,1,T)\n",
    "\n",
    "## Basis system \n",
    "bs = Bspline((-1,1), 25, 4)\n",
    "B = np.kron(bs(np.linspace(-1,1,S1)), bs(np.linspace(-1,1,S2)))\n",
    "J = np.kron(np.eye(bs.K), bs.penalty(0)) + np.kron(bs.penalty(0), np.eye(bs.K))\n",
    "\n",
    "## Penalties for regularisation and mafr. \n",
    "NDERIV = 2\n",
    "P = np.kron(np.eye(bs.K), bs.penalty(NDERIV)) + np.kron(bs.penalty(NDERIV), np.eye(bs.K))\n",
    "LOG_LAMBDA = -6.0\n",
    "\n",
    "## Maximum forecast size, training data set, and components to use.\n",
    "STEPS = 25\n",
    "N_INIT = 90\n",
    "N_COMP = 3\n",
    "\n",
    "## Constant simulated data (nsimulations X datasets)\n",
    "SIM_PATH = '../data/surf_disp.npz'\n",
    "data = np.load(SIM_PATH)\n",
    "Y = data['SD']\n",
    "\n",
    "## Noise Generation\n",
    "def generateNoise(label):\n",
    "    if label=='ln':\n",
    "        noise = whiteNoise(5.0, Y.shape)\n",
    "    elif label =='hn':\n",
    "        noise = whiteNoise(20.0, Y.shape)\n",
    "    else:\n",
    "        noise = structNoise(20.0, (Y.shape[0], S1, S2), l=0.5**2, scale_percent=10)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "The following codeblock runs the forecasting using an each decomposition for each of the low noise, high noise and structure noise scenario. We complete this for 100 simulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:16:30<00:00, 45.91s/it]\n"
     ]
    }
   ],
   "source": [
    "NSIM = 100\n",
    "noise_labels = ['ln', 'hn', 'sn']\n",
    "models = ['fpca', 'mafr','reg-fpca','reg-mafr']\n",
    "results={m+'_'+n:np.zeros((NSIM, np.max(STEPS))) for m in models for n in noise_labels}\n",
    "for i in tqdm.tqdm(np.arange(NSIM)):\n",
    "    for label in noise_labels:\n",
    "        noise = generateNoise(label)\n",
    "        Y_e = Y + noise\n",
    "        for model in models:\n",
    "            ll = LOG_LAMBDA if model.startswith('reg') else -14.0\n",
    "            mafr_ind = True if 'mafr' in model else False\n",
    "            Y_train = Y_e[:N_INIT]\n",
    "            x_ob = t[:N_INIT]\n",
    "            x_new = t[N_INIT:(N_INIT+STEPS)]\n",
    "            Cbar, zeta, scores, w = fpca(Y_train.T, B, P, ll, NDERIV, J, N_COMP)\n",
    "            if mafr_ind:\n",
    "                zeta, scores, U = mafr(zeta, scores, P)\n",
    "            mu_fors = []\n",
    "            V_fors = []\n",
    "            for score in scores.T:\n",
    "                gp = GP(Matern(nu=1.5, rho=1.0, sigma=1.0))\n",
    "                gp.fit(x_ob, score.T, bounds=[(-6,2), (-6,2), (-6, 2)], n_init=100)\n",
    "                mu_for, V_for = gp.posterior(x_new)\n",
    "                mu_fors.append(mu_for)\n",
    "                V_fors.append(np.diag(V_for))\n",
    "            recon = np.matmul(np.matmul(B, zeta), mu_fors) + np.matmul(B, Cbar)[:, np.newaxis]\n",
    "            results[model+'_'+label][i,: ] = np.sqrt(np.mean((Y[N_INIT:(N_INIT+STEPS)].T-recon)**2, axis=0))\n",
    "for key in results.keys():\n",
    "    np.savez('../results/surf_disp_'+key+'.npz', results=results[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dftsm",
   "language": "python",
   "name": "dftsm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
